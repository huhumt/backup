我曾经对 Tesla 的 Autopilot 做过一些技术上，责任上的分析，可是我发现对于自动驾驶车的责任问题仍然缺乏一个完全使人信服的说法。最近思考很多机器视觉方面的问题，最终导致了这篇文章的产生。在这篇文章里，我试图使用逻辑和概率论来分析自动驾驶车的责任和风险问题。
自动驾驶领域最著名，最不负责任的人，当属 Tesla 的 Elon Musk 先生了。他不但总是对 Tesla 的 Autopilot 进行夸大的宣传，吹嘘“全自动驾驶很快就要实现了”，让人误解 Autopilot 的能力，死了人之后还要在网上发话扭曲人们的逻辑和伦理。Tesla 公司总是抓住“车主没有及时接管”等各种借口，逃脱对事故的责任。
几乎每次 Autopilot 判断错误撞死了人，Elon Musk 都会出来说：“自动驾驶的事故率还是远远低于人类驾驶员！” 很多书呆子极客会听信他的“事故率”，为他的所谓“高科技”欢呼而忽略死者，可是他们不明白，这些大范围的统计数字对于事故责任分析，对于 Autopilot 的风险评估，都是没用的。
他的说法就相当于在说：“我活了这么久，为这么多客户服务，没杀过其中任何一个，我杀人的概率非常低，低于全国的谋杀犯罪率，所以我现在杀了你不用负责。” 先不说 Autopilot 的事故率是否真的那么低。即使它事故率是很低，难道弄死了人就可以不负责，甚至不受谴责吗？
到底 Tesla 有没有责任，我们可以使用逻辑学，使用因果关系的“反事实分析”（counterfactual analysis）。如果驾驶员没有使用 Autopilot 而是自己开车，这次事故还会不会发生？如果不会发生，那么我们得到因果关系：Autopilot 导致了事故。不管其他人用 Autopilot 有没有出事故，事故占多大比例，面对这里的因果关系都是无关紧要的。
因果关系等于责任。
如果是 Autopilot 导致了事故，即使总共只发生了一次事故，都该它的设计者 Tesla 公司负责。很多人都是混淆了“责任”和“事故率”，所以才会继续支持 Elon Musk 和 Tesla 的欺诈行为。很多人总是以为“自动驾驶可能会降低全国的车祸率”，从而认为 Autopilot 引起少数几次车祸问题不大，而不明白“事故率”跟“责任”和“事故再次发生的风险”，完全是两码事。
为什么我强调“责任”的问题呢？因为人如果自己开车不小心出了车祸，伤到自己，他自己是可以接受的，因为是自己的责任。可是要是 Autopilot 判断错误引起车祸撞伤了自己，那么对于车主来说就是不可接受的。任何人都应该明白这个道理吧？这就跟自己开车不小心撞了受了伤，和出租车司机不小心撞了导致你受伤的差别一样。你会告那个出租车司机，你却不会上法庭告自己。简单吧？
如果拿事故率说事，航空业的事故率远远低于汽车业了吧？可是为什么全世界好多年才发生一次空难，却每一次都带来那么多的恐慌，进行那么严格的调查，追究责任呢？就是因为我之前分析的，责任和事故率完全是两回事。任何人或者交通工具本身的问题导致了事故引起其他人死伤，都是不会被放过的，不管他的总体事故率如何低，都一样要被惩罚。
另外责任的大小，新闻舆论的大小，也与同一个事故的死伤人数有关。如果是一个人开车不小心撞了，死了两个人，人们不会特别关注，因为“杀伤力”太小，只有 1:2。一年发生很多起这样的事故，就算总共死了超过 200 人，都不会引起人们关注，因为杀伤力 100:200=1:2，还是比较小。而且人们知道那是个别情况，小概率事件，只要自己小心开车，就不大可能会发生在自己身上。
可是如果一个飞行员操作失误，或者飞机故障导致 200 人丧生，就严重很多。首先，同一事故死亡人数很多，杀伤力为 1:200。人们会开始怀疑那家航空公司的飞行员是不是培训不够严格，或者是不是有被迫加班，疲劳驾驶的情况。人们会怀疑那个型号的飞机是不是全都有问题。所以这么一次空难，导致了“近期再次发生空难”的概率（所谓后验概率）大幅度上升。这就是人们看到空难新闻如此关心的原因。
为什么波音 737 MAX 的空难引起这么大的风波呢？为什么以前的波音飞机空难都没有如此大的影响呢？甚至 9.11 事件发生的时候，两架波音飞机撞了大楼，引起几千人丧命，都没有对波音公司造成如此严重的打击。因为由于飞机的设计错误而导致的空难，和由于飞行员或者其它原因（比如劫机）而导致的空难，对“近期再次发生空难”的后验概率影响程度是不一样的。
如果是因为劫机引起空难，由于劫机的概率如此之小，特别是如果劫机发生在某个落后国家，人们知道那大概不会发生在自己身上，就不会很担心。如果由于某一个飞行员操作失误引起空难，人们的担心程度就大一些了。人们会严格调查飞机出事原因，调查那个航空公司，如果发现只是个别情况，那可以推断同样的空难不会再次发生。当然，很多人还是会因此回避那个航空公司，因为可能是他们迫使飞行员疲劳驾驶导致的，所以同样的事情可能发生在该公司的其它飞行员身上。可是要是飞机本身的设计原因，质量问题引起了空难，那么同样的故障可能在近期发生在所有同一型号的飞机上，那事就很大了，知情的人都会避免乘坐同一型号的飞机。
这就是为什么每年几万起其它车祸没什么人关心，而 Autopilot 引起一两次车祸就这么多新闻舆论。因为要是车祸是由于 Autopilot 引起的，那么同样的车祸就可能发生在所有使用 Autopilot 的 Tesla 车主身上，引起“Autopilot 再次发生车祸”的后验概率大大提高。
这里的核心问题就在于，到底是人开车还是 Autopilot 开车。因为每个人都是不一样的，有的人开车很稳而有的人很鲁莽，他们之间没有联系，是“独立随机变量”。而 Autopilot 都是一样的软件，有一模一样的行为方式，所以使用 Autopilot 的 Tesla 车不是独立的变量，而是“相关随机变量”，它们通过 Autopilot 关联在一起。某个人自己开车不小心出车祸，不会引起其他人也出同样的车祸，而 Autopilot 要是引起了车祸，那么所有使用 Autopilot 的车主遇到同样的情况方，就很可能发生同样的车祸。
如果你学过概率论，那么使用 Autopilot 的车主出事的“后验概率”（<a href="https://en.wikipedia.org/wiki/Posterior_probability">posterior probability</a>）会因为“Autopilot 引起一次车祸”这一事件的发生而大幅度提高，而如果只是普通的汽车，那么车主出事的后验概率不会因为其它同型号车出事而大幅度提高。写成数学公式就是：
P(其它使用 Autopilot 的车主出车祸 | Autopilot 引起一次车祸)
远大于
P(其它非自动车出车祸 | 一辆非自动车出车祸)
事故的起因不同，后验概率也就随之不同。同理，对于之前的空难问题，你也可以使用类似的条件概率分析。再次发生空难的“后验概率”，根据某一次空难的起因，会有很大的差别。
P(近期再次发生空难 | 飞机设计错误引起一次空难)
远大于
P(近期再次发生空难 | 飞行员操作失误引起一次空难)
大于
P(近期再次发生空难 | 劫机引起一次空难)
面对“Autopilot 有一定概率会要了你的命”这一事实，不管 Autopilot 的总体事故率有多低，甚至像 Elon Musk 说的低于全国车祸率，对于 Tesla 车主来说都是毫无意义的。一是因为“责任”：车主们可以允许自己要了自己的命，却不允许 Autopilot 或者其他人要了自己的命。二是因为“概率”（风险），不管全国的事故率是多少，自己开车的事故率一般只跟自己开车的小心程度有关系，也就是说自己开车出事故的概率独立于全国事故率。而使用 Autopilot，自己的事故率就受到 Autopilot 设计的影响，从而跟 Autopilot 的平均事故率差不多了。
Autopilot 的事故率真的低吗？你可以自己研究一下。如果你算对了数学，恐怕它的事故率并不低。举一个例子，普通人只计算了事故的数目与 Autopilot 导航的总里程的比例，却忽视了那些由于驾驶员及时接管而避免了的事故的数目。另外 Tesla 属于比较贵的车，买车的人属于对自己比较负责的人，所以事故率不应该跟所有车的事故率比，而应该跟没有安装自动驾驶技术的奔驰，保时捷一类的车的事故率对比。
每一次 Autopilot 相关的事故，Tesla 公司都会在事后散布新闻说是驾驶者开车不认真，手没有在方向盘上准备随时接管，所以不是 Autopilot 的责任。驾驶者是否认真在开车，人死了无所对证，但这些全都成为了 Tesla 公司推脱责任的借口。
如果发现 Autopilot 判断失误，你真来得及接管吗，你能在那么短的时间内做出正确的反应吗？就算你双手都在方向盘上，前面有辆大卡车正在转弯，车到了多近的地方不减速，你才会意识到它出错了，打算接管呢？恐怕到了你发现它根本不会刹车的时候，狠命踩下刹车就已经晚了。所以要求车主随时接管，根本就不是一个合理的要求，不应该作为 Tesla 免责的理由。
所以 Tesla 不但视觉技术不行，而且人品和诚信都很成问题。我还没有见过一个汽车公司如此急于推脱责任的，一般都是积极配合调查，勇于承担责任，及时整改，这样才可能得到公众的信任。
